{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indeed Job Manager\n",
    "\n",
    "- A text interface that helps users:\n",
    "    1. Find desired jobs from indeed\n",
    "    2. Quickly apply to interested jobs\n",
    "    3. To keep track of application history\n",
    "\n",
    "### User options\n",
    "\n",
    "- Users provide:\n",
    "    - Indeed Starting Urls: list\n",
    "        - starting url starts from indeed and can contain filters like\n",
    "            - job title\n",
    "            - full time/ parttime\n",
    "            - experience level\n",
    "            - ex: \"https://www.indeed.com/jobs?q=data+engineer&jt=fulltime&explvl=entry_level\"\n",
    "    - Title keywords: list\n",
    "        - jobs must contain one of these key words\n",
    "    - Must have keywords: list of lists\n",
    "        - jobs must conain one group of eay keyword in the job description\n",
    "    - Nice to have keywords: list\n",
    "        - db registers all the nice to have keywords found in the job description\n",
    "    - Resume ID: string\n",
    "        - keep track of what resume was sent to a company\n",
    "    - Job Tab Amount: int\n",
    "        - toggle how many pages you want to apply to open and apply to at a time\n",
    "\n",
    "### Project components\n",
    "\n",
    "##### Jobs ETL\n",
    "- scrapes indeed using starting url\n",
    "- filters jobs by keywords\n",
    "- labels jobs and stores them into a json database\n",
    "\n",
    "##### Semi-Automated Job applier\n",
    "- User gets N desired jobs that opened in tabs\n",
    "- User informs system which jobs were applied to\n",
    "- Job is successfuly registered in the database\n",
    "\n",
    "##### Job Tracker (Not Implemented yet)\n",
    "- Tracks where and how many jobs have been applied to\n",
    "- Tracks how many false positives there have been\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "import datetime\n",
    "from process_jobs import process_jobs, load_database_jobs, write_file\n",
    "from job_applier.scraper import Scraper\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def menu():\n",
    "    '''main menu'''\n",
    "    selection = input(MENU_PROMPT)\n",
    "    while selection != 'quit':\n",
    "        if selection == 'scrape':\n",
    "            scrape_new_jobs()\n",
    "        elif selection == 'apply':\n",
    "            jobs_db = load_database_jobs()\n",
    "            new_jobs = get_new_jobs(jobs_db)\n",
    "            print(f'there are currently {len(new_jobs)} jobs')\n",
    "            for index in range(0, len(new_jobs), JOB_TAB_AMOUNT):      \n",
    "                current_jobs = get_current_jobs(new_jobs, index)\n",
    "                open_job_urls(current_jobs)\n",
    "                print_job_info(current_jobs)\n",
    "                selection_2 = input(APPLY_PROMPT)\n",
    "                while not is_valid_amount(selection_2):\n",
    "                    selection_2 = input(APPLY_PROMPT)\n",
    "                if selection_2 == 'quit':\n",
    "                    break\n",
    "                if selection_2 == 'skip':\n",
    "                    continue\n",
    "                selected_index = parse_input(selection_2)\n",
    "                commit_jobs(selected_index, current_jobs, jobs_db)\n",
    "        elif selection == 'quit':\n",
    "            break\n",
    "        selection = input(MENU_PROMPT)\n",
    "\n",
    "def scrape_new_jobs():\n",
    "    '''web scrapes jobs, process them by keywords, then stores them in db'''\n",
    "    print('scraping jobs... This may take some time...')\n",
    "    clear_output(wait=True)\n",
    "    #!python scrape_jobs.py\n",
    "    clear_output(wait=False)\n",
    "    scraper = Scraper()\n",
    "    scraper.run_spiders(INDEED_STARTING_URLS)\n",
    "    process_jobs(TITLE_KEYWORDS, MUST_HAVE_KEYWORD_GROUPS, NICE_TO_HAVE_KEYWORDS)\n",
    "    clear_output(wait=False)\n",
    "\n",
    "def get_new_jobs(jobs_db):\n",
    "    '''gets jobs user is intersted in that is sorted by most recent, and amount of keywords'''\n",
    "    filtered_jobs = [job for job in jobs_db if job['interested'] == True and job['applied_to'] == False]\n",
    "    sorted_jobs = sorted(filtered_jobs, key = lambda x: (x['scraped_on'], len(x['nice_keywords'])), reverse = True)\n",
    "    return sorted_jobs\n",
    "\n",
    "def get_current_jobs(new_jobs, index):\n",
    "    '''gets jobs from a list at JOB_TAB_AMOUNT at a time'''\n",
    "    if index + JOB_TAB_AMOUNT <= len(new_jobs):\n",
    "        return new_jobs[index:index+JOB_TAB_AMOUNT]\n",
    "    else:\n",
    "        return new_jobs[index:]\n",
    "\n",
    "def open_job_urls(jobs):\n",
    "    '''opens jobs in new tabs'''\n",
    "    for job in jobs:\n",
    "        url = job['url']\n",
    "        print(url)\n",
    "        webbrowser.open_new_tab(url)\n",
    "\n",
    "def print_job_info(jobs):\n",
    "    for idx, job in enumerate(jobs):\n",
    "        print(f'{idx}. {job[\"title\"]}: {job[\"nice_keywords\"]}')\n",
    "\n",
    "def is_valid_amount(input):\n",
    "    input = input.split()\n",
    "    if input[0] == 'quit' or input[0] == 'skip':\n",
    "        return True\n",
    "    if input[0] != 'commit':\n",
    "        return False\n",
    "    if len(input) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        if not all([value.isnumeric() for value in input[1:]]):\n",
    "            return False\n",
    "        if any([int(value) > JOB_TAB_AMOUNT for value in input[1:]]):\n",
    "            return False\n",
    "        return input[1:]\n",
    "\n",
    "def parse_input(input):\n",
    "    '''filters which job forms were of interest to the user'''\n",
    "    input = input.split()\n",
    "    # if commit is send, assumes all jobs were applied to\n",
    "    if len(input) == 1:\n",
    "        return list(range(JOB_TAB_AMOUNT))\n",
    "    else:\n",
    "        return [int(value) for value in input[1:]]\n",
    "\n",
    "def commit_jobs(applied_to_list, applied_to_jobs, jobs_db):\n",
    "    '''filters out which jobs the user was interested in updates db'''\n",
    "    for idx, job in enumerate(applied_to_jobs):\n",
    "        if idx in applied_to_list:\n",
    "            register_job(job, jobs_db)\n",
    "        else:\n",
    "            register_not_interested(job, jobs_db)\n",
    "    database_jobs_path = 'database_jobs.json'\n",
    "    write_file(database_jobs_path, jobs_db)\n",
    "\n",
    "def register_job(current_job, jobs_db):\n",
    "    '''user successfully applied to job'''\n",
    "    jobs_id = current_job['info']\n",
    "    for job in reversed(jobs_db):\n",
    "        if jobs_id in job['info']:\n",
    "            job['applied_to'] = True\n",
    "            job['applied_on'] = str(datetime.date.today())\n",
    "            job['resume_sent'] = RESUME\n",
    "\n",
    "def register_not_interested(current_jobs, jobs_db):\n",
    "    '''keeps track of jobs that should have been applied to but were not'''\n",
    "    jobs_id = current_jobs['info']\n",
    "    for job in reversed(jobs_db):\n",
    "        if jobs_id in job['info']:\n",
    "            job['interested'] = False\n",
    "            job['false positive'] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type \"scrape\" to scrape new jobs, \"apply\" to apply to new jobs, or \"quit\" to quit:  apply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are currently 140 jobs\n",
      "https://www.indeed.com/viewjob?jk=9b1526f9a1b09b9c&from=serp&vjs=3\n",
      "https://www.indeed.com/viewjob?cmp=Pediatric-Associates-Florida&t=Data+Engineer&jk=1cf657303c920589&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=507637d46f933d47&from=serp&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=e2284cae54cc43a6&from=serp&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=78c9041ef6929817&from=serp&vjs=3\n",
      "0. Data engineer: ['etl', 'pipeline']\n",
      "1. Data Engineer (Business Analytics Department): ['etl', 'pipeline']\n",
      "2. Data Engineer: ['pipeline']\n",
      "3. Data Engineer: ['etl']\n",
      "4. Junior DevOps Engineer: ['pipeline']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type \"commit\" to commit all, \"commit # #\" to commit only those #, \"skip\", or \"quit\":  skip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/viewjob?jk=9625cab3cbf005df&from=serp&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=c42c47663d07e845&from=serp&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=6853ce0179984c44&from=serp&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=7179a7e983d02cf6&from=serp&vjs=3\n",
      "https://www.indeed.com/viewjob?jk=695db9e2231f8c07&from=serp&vjs=3\n",
      "0. Data Engineer II: ['etl']\n",
      "1. PYTHON DATA ENGINEER: ['pipeline']\n",
      "2. Data QA Engineer: ['etl']\n",
      "3. Data Engineer: ['etl']\n",
      "4. ML/AI Engineer: ['pandas']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type \"commit\" to commit all, \"commit # #\" to commit only those #, \"skip\", or \"quit\":  quit\n",
      "Type \"scrape\" to scrape new jobs, \"apply\" to apply to new jobs, or \"quit\" to quit:  quit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# jobs must contain one of these titles\n",
    "TITLE_KEYWORDS = ['engineer', 'software-engineer', 'dataengineer', 'data-engineer', 'data']\n",
    "\n",
    "# jobs must contain one group keyword in job description for every group\n",
    "MUST_HAVE_KEYWORD_GROUPS = [['python', 'python3']]\n",
    "\n",
    "# job will update all nice to have keywords founds\n",
    "NICE_TO_HAVE_KEYWORDS = ['pandas', 'webscraping', 'dash', 'scrapy', 'etl', 'pipeline']\n",
    "\n",
    "# Starting urls from indeed siete, can add job titles, experience level, etc\n",
    "INDEED_STARTING_URLS = [\n",
    "        \"https://www.indeed.com/jobs?q=data+engineer&jt=fulltime&explvl=entry_level\",\n",
    "        \"https://www.indeed.com/jobs?q=software+engineer&jt=fulltime&explvl=entry_level\",\n",
    "    ]\n",
    "\n",
    "# amount of jobs opening at a tmie\n",
    "JOB_TAB_AMOUNT = 5\n",
    "\n",
    "# resume you are sending out\n",
    "RESUME = 'V1.00'\n",
    "\n",
    "MENU_PROMPT = 'Type \"scrape\" to scrape new jobs, \"apply\" to apply to new jobs, or \"quit\" to quit: '\n",
    "APPLY_PROMPT = 'Type \"commit\" to commit all, \"commit # #\" to commit only those #, \"skip\", or \"quit\": '\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    menu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
